"""
AIé…å›¾ç”Ÿæˆæ¨¡å—
- é€šè¿‡ OpenAI å…¼å®¹ API è°ƒç”¨å›¾åƒç”Ÿæˆæ¨¡å‹
- æ”¯æŒæœ¬åœ°é…ç½®çš„ Gemini ç­‰æ¨¡å‹
"""

import base64
import os
import time
from dataclasses import dataclass
from pathlib import Path

from openai import OpenAI


@dataclass
class ImageConfig:
    """å›¾ç‰‡ç”Ÿæˆé…ç½®"""
    width: int = 1024
    height: int = 768
    num_inference_steps: int = 30
    guidance_scale: float = 7.5
    seed: int | None = None


@dataclass
class GeneratedImage:
    """ç”Ÿæˆçš„å›¾ç‰‡"""
    prompt: str
    path: Path
    width: int
    height: int
    model: str


class ImageGenerator:
    """AIé…å›¾ç”Ÿæˆå™¨ - é€šè¿‡ OpenAI å…¼å®¹ API è°ƒç”¨"""

    def __init__(
        self,
        model: str = "google/gemini-2.0-flash-preview-image-generation",
        api_key: str | None = None,
        base_url: str | None = None,
        output_dir: Path | str = "./output/images",
    ):
        self.model_id = model
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # è®¾ç½® API é…ç½®ï¼ˆå»¶è¿Ÿæ£€æŸ¥ï¼‰
        self._api_key = api_key or os.getenv("OPENAI_API_KEY")
        self._base_url = base_url or os.getenv("OPENAI_BASE_URL")
        self._client = None

    @property
    def client(self):
        """å»¶è¿Ÿåˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯"""
        if self._client is None:
            if not self._api_key:
                raise ValueError("éœ€è¦è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
            self._client = OpenAI(
                api_key=self._api_key,
                base_url=self._base_url,
            )
        return self._client

    def generate(
        self,
        prompt: str,
        config: ImageConfig | None = None,
        output_name: str | None = None,
        enhance_prompt: bool = True,
    ) -> GeneratedImage:
        """
        ç”Ÿæˆé…å›¾

        Args:
            prompt: å›¾ç‰‡æè¿°prompt
            config: ç”Ÿæˆé…ç½®
            output_name: è¾“å‡ºæ–‡ä»¶å
            enhance_prompt: æ˜¯å¦å¢å¼ºprompt

        Returns:
            ç”Ÿæˆçš„å›¾ç‰‡ä¿¡æ¯
        """
        config = config or ImageConfig()

        # å¢å¼ºpromptï¼ˆé’ˆå¯¹ç§‘æŠ€æ–‡ç« é…å›¾ä¼˜åŒ–ï¼‰
        if enhance_prompt:
            prompt = self._enhance_prompt(prompt)

        print(f"ğŸ¨ æ­£åœ¨ç”Ÿæˆé…å›¾...")
        print(f"   æ¨¡å‹: {self.model_id}")
        print(f"   Prompt: {prompt[:100]}...")

        # é€šè¿‡ OpenAI å…¼å®¹ API è°ƒç”¨å›¾åƒç”Ÿæˆ
        try:
            response = self.client.chat.completions.create(
                model=self.model_id,
                messages=[
                    {
                        "role": "user",
                        "content": f"Generate an image: {prompt}"
                    }
                ],
            )

            # ä»å“åº”ä¸­æå–å›¾ç‰‡æ•°æ®
            image_data = None
            message = response.choices[0].message

            # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡å†…å®¹
            if hasattr(message, 'content') and message.content:
                # å°è¯•ä» content ä¸­æå– base64 å›¾ç‰‡
                content = message.content
                if isinstance(content, list):
                    for part in content:
                        if isinstance(part, dict):
                            if part.get('type') == 'image_url':
                                image_url = part.get('image_url', {}).get('url', '')
                                if image_url.startswith('data:image'):
                                    # æå– base64 æ•°æ®
                                    base64_data = image_url.split(',')[1] if ',' in image_url else image_url
                                    image_data = base64.b64decode(base64_data)
                                    break
                            elif part.get('type') == 'image' and part.get('data'):
                                image_data = base64.b64decode(part['data'])
                                break

            # å¦‚æœå“åº”ä¸­æœ‰ inline_dataï¼ˆGemini é£æ ¼ï¼‰
            if image_data is None and hasattr(response, 'candidates'):
                for candidate in response.candidates:
                    if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                        for part in candidate.content.parts:
                            if hasattr(part, 'inline_data') and part.inline_data:
                                image_data = part.inline_data.data
                                break

            if image_data is None:
                raise ValueError("API æ²¡æœ‰è¿”å›å›¾ç‰‡æ•°æ®ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒå›¾åƒç”Ÿæˆ")

            # ä¿å­˜å›¾ç‰‡
            image_path = self._save_image(image_data, output_name)

            print(f"âœ… é…å›¾ç”ŸæˆæˆåŠŸ: {image_path}")

            return GeneratedImage(
                prompt=prompt,
                path=image_path,
                width=config.width,
                height=config.height,
                model=self.model_id,
            )

        except Exception as e:
            print(f"âŒ é…å›¾ç”Ÿæˆå¤±è´¥: {e}")
            raise

    def _enhance_prompt(self, prompt: str) -> str:
        """å¢å¼ºpromptï¼Œä¼˜åŒ–ç”Ÿæˆæ•ˆæœ"""
        # æ·»åŠ è´¨é‡å’Œé£æ ¼ä¿®é¥°è¯
        enhancements = [
            "high quality",
            "professional illustration",
            "clean design",
            "modern style",
        ]

        # æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å«è¿™äº›è¯
        prompt_lower = prompt.lower()
        additions = [e for e in enhancements if e not in prompt_lower]

        if additions:
            prompt = f"{prompt}, {', '.join(additions[:2])}"

        return prompt

    def _save_image(self, image_data: bytes, output_name: str | None = None) -> Path:
        """ä¿å­˜ç”Ÿæˆçš„å›¾ç‰‡"""
        # ç”Ÿæˆæ–‡ä»¶å
        if output_name is None:
            timestamp = int(time.time())
            output_name = f"generated_{timestamp}.png"

        if not output_name.endswith((".png", ".jpg", ".jpeg", ".webp")):
            output_name += ".png"

        output_path = self.output_dir / output_name
        output_path.write_bytes(image_data)

        return output_path

    def generate_cover(
        self,
        title: str,
        topic: str = "AI",
        style: str = "tech",
    ) -> GeneratedImage:
        """
        ç”Ÿæˆæ–‡ç« å°é¢å›¾

        Args:
            title: æ–‡ç« æ ‡é¢˜
            topic: ä¸»é¢˜
            style: é£æ ¼

        Returns:
            ç”Ÿæˆçš„å°é¢å›¾
        """
        # æ„å»ºå°é¢prompt
        style_prompts = {
            "tech": "futuristic technology, digital art, abstract neural network visualization, blue and purple gradient",
            "minimal": "minimalist design, clean white background, simple geometric shapes",
            "academic": "academic illustration, scientific diagram style, professional",
            "creative": "creative abstract art, colorful, dynamic composition",
        }

        style_desc = style_prompts.get(style, style_prompts["tech"])

        prompt = f"Article cover image about {topic}: {title}. {style_desc}"

        # å°é¢å›¾ä½¿ç”¨16:9æ¯”ä¾‹
        config = ImageConfig(width=1200, height=675)

        return self.generate(prompt, config, enhance_prompt=True)

    def batch_generate(
        self,
        prompts: list[str],
        config: ImageConfig | None = None,
    ) -> list[GeneratedImage]:
        """
        æ‰¹é‡ç”Ÿæˆé…å›¾

        Args:
            prompts: promptåˆ—è¡¨
            config: ç”Ÿæˆé…ç½®

        Returns:
            ç”Ÿæˆçš„å›¾ç‰‡åˆ—è¡¨
        """
        results = []

        for i, prompt in enumerate(prompts):
            print(f"\n[{i + 1}/{len(prompts)}] ç”Ÿæˆé…å›¾...")
            try:
                output_name = f"batch_{i + 1}.png"
                image = self.generate(prompt, config, output_name)
                results.append(image)
            except Exception as e:
                print(f"âš ï¸ è·³è¿‡å¤±è´¥çš„ç”Ÿæˆ: {e}")

            # é¿å…APIé™æµ
            if i < len(prompts) - 1:
                time.sleep(1)

        return results


# ä¾¿æ·å‡½æ•°
def generate_image(
    prompt: str,
    model: str = "google/gemini-2.0-flash-preview-image-generation",
    output_dir: str = "./output/images",
) -> Path:
    """ç”Ÿæˆé…å›¾çš„ä¾¿æ·å‡½æ•°"""
    generator = ImageGenerator(model=model, output_dir=output_dir)
    result = generator.generate(prompt)
    return result.path


if __name__ == "__main__":
    # æµ‹è¯•
    generator = ImageGenerator()

    # ç”Ÿæˆæµ‹è¯•å›¾ç‰‡
    result = generator.generate(
        "Abstract visualization of transformer neural network architecture, "
        "attention mechanism flowing between nodes, digital art style"
    )
    print(f"\nç”ŸæˆæˆåŠŸ: {result.path}")
