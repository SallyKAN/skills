"""
æ–‡ç« ç”Ÿæˆæ¨¡å—
- è°ƒç”¨LLMç”Ÿæˆåˆç¨¿
- æ”¯æŒAnthropicå’ŒOpenAI
"""

import os
from dataclasses import dataclass
from pathlib import Path
from string import Template

from anthropic import Anthropic
from openai import OpenAI

from ..parser.pdf_parser import PaperContent


@dataclass
class ArticleConfig:
    """æ–‡ç« ç”Ÿæˆé…ç½®"""
    language: str = "zh-CN"
    style: str = "é€šä¿—æ˜“æ‡‚ã€æ·±å…¥æµ…å‡º"
    audience: str = "å¯¹AIæ„Ÿå…´è¶£çš„æŠ€æœ¯çˆ±å¥½è€…"
    max_tokens: int = 8192


@dataclass
class GeneratedArticle:
    """ç”Ÿæˆçš„æ–‡ç« """
    title: str
    content: str  # Markdownæ ¼å¼
    image_placeholders: list[dict]  # éœ€è¦é…å›¾çš„ä½ç½®
    word_count: int
    paper_title: str


class ArticleWriter:
    """æ–‡ç« ç”Ÿæˆå™¨"""

    def __init__(
        self,
        provider: str = "anthropic",
        model: str | None = None,
        api_key: str | None = None,
        prompts_dir: Path | str = "./prompts",
    ):
        self.provider = provider
        self.prompts_dir = Path(prompts_dir)

        if provider == "anthropic":
            self.model = model or "claude-sonnet-4-20250514"
            self.client = Anthropic(api_key=api_key or os.getenv("ANTHROPIC_API_KEY"))
        elif provider == "openai":
            self.model = model or "gpt-4o"
            self.client = OpenAI(api_key=api_key or os.getenv("OPENAI_API_KEY"))
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„provider: {provider}")

        # åŠ è½½æç¤ºè¯æ¨¡æ¿
        self.translate_prompt = self._load_prompt("translate.md")

    def _load_prompt(self, filename: str) -> str:
        """åŠ è½½æç¤ºè¯æ¨¡æ¿"""
        prompt_path = self.prompts_dir / filename
        if prompt_path.exists():
            return prompt_path.read_text(encoding="utf-8")
        else:
            raise FileNotFoundError(f"æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨: {prompt_path}")

    def generate(
        self,
        paper: PaperContent,
        config: ArticleConfig | None = None,
        citations: int | None = None,
    ) -> GeneratedArticle:
        """
        æ ¹æ®è®ºæ–‡å†…å®¹ç”Ÿæˆæ–‡ç« åˆç¨¿

        Args:
            paper: è§£æåçš„è®ºæ–‡å†…å®¹
            config: æ–‡ç« é…ç½®
            citations: è®ºæ–‡å¼•ç”¨é‡ï¼ˆå¯é€‰ï¼‰

        Returns:
            ç”Ÿæˆçš„æ–‡ç« 
        """
        config = config or ArticleConfig()

        # æ„å»ºæç¤ºè¯
        prompt = self._build_prompt(paper, config, citations)

        print(f"ğŸ“ æ­£åœ¨ç”Ÿæˆæ–‡ç« åˆç¨¿...")
        print(f"   æ¨¡å‹: {self.provider}/{self.model}")

        # è°ƒç”¨LLM
        content = self._call_llm(prompt, config.max_tokens)

        # è§£æç”Ÿæˆçš„å†…å®¹
        article = self._parse_generated_content(content, paper.title)

        print(f"âœ… åˆç¨¿ç”Ÿæˆå®Œæˆ")
        print(f"   æ ‡é¢˜: {article.title}")
        print(f"   å­—æ•°: {article.word_count}")
        print(f"   é…å›¾ä½ç½®: {len(article.image_placeholders)}å¤„")

        return article

    def _build_prompt(
        self,
        paper: PaperContent,
        config: ArticleConfig,
        citations: int | None,
    ) -> str:
        """æ„å»ºå®Œæ•´çš„æç¤ºè¯"""
        # å‡†å¤‡è®ºæ–‡å†…å®¹æ‘˜è¦
        paper_content = self._prepare_paper_content(paper)

        # æ›¿æ¢æ¨¡æ¿å˜é‡
        prompt = self.translate_prompt
        prompt = prompt.replace("{{title}}", paper.title)
        prompt = prompt.replace("{{authors}}", ", ".join(paper.authors[:10]))
        prompt = prompt.replace("{{date}}", paper.metadata.get("creationDate", "æœªçŸ¥"))
        prompt = prompt.replace("{{citations}}", str(citations) if citations else "æœªçŸ¥")
        prompt = prompt.replace("{{content}}", paper_content)

        # æ·»åŠ é…ç½®ä¿¡æ¯
        config_text = f"""
## å†™ä½œé…ç½®
- ç›®æ ‡è¯­è¨€: {config.language}
- å†™ä½œé£æ ¼: {config.style}
- ç›®æ ‡è¯»è€…: {config.audience}
"""
        prompt = prompt.replace("## è®ºæ–‡ä¿¡æ¯", config_text + "\n## è®ºæ–‡ä¿¡æ¯")

        return prompt

    def _prepare_paper_content(self, paper: PaperContent) -> str:
        """å‡†å¤‡è®ºæ–‡å†…å®¹ï¼ˆæ§åˆ¶é•¿åº¦ï¼‰"""
        parts = []

        # æ‘˜è¦
        if paper.abstract:
            parts.append(f"## Abstract\n{paper.abstract}")

        # ä¸»è¦ç« èŠ‚
        for title, content in paper.sections.items():
            # é™åˆ¶æ¯ä¸ªç« èŠ‚çš„é•¿åº¦
            truncated = content[:3000] + "..." if len(content) > 3000 else content
            parts.append(f"## {title}\n{truncated}")

        # å›¾è¡¨ä¿¡æ¯
        if paper.figures:
            fig_info = "\n## è®ºæ–‡å›¾è¡¨\n"
            for fig in paper.figures[:10]:  # æœ€å¤š10ä¸ªå›¾
                fig_info += f"- Figure {fig.index} (Page {fig.page_num})"
                if fig.caption:
                    fig_info += f": {fig.caption}"
                fig_info += "\n"
            parts.append(fig_info)

        full_content = "\n\n".join(parts)

        # æ€»é•¿åº¦æ§åˆ¶ï¼ˆé¿å…è¶…å‡ºä¸Šä¸‹æ–‡é™åˆ¶ï¼‰
        if len(full_content) > 30000:
            full_content = full_content[:30000] + "\n\n[å†…å®¹å·²æˆªæ–­...]"

        return full_content

    def _call_llm(self, prompt: str, max_tokens: int) -> str:
        """è°ƒç”¨LLMç”Ÿæˆå†…å®¹"""
        if self.provider == "anthropic":
            response = self.client.messages.create(
                model=self.model,
                max_tokens=max_tokens,
                messages=[{"role": "user", "content": prompt}],
            )
            return response.content[0].text

        elif self.provider == "openai":
            response = self.client.chat.completions.create(
                model=self.model,
                max_tokens=max_tokens,
                messages=[{"role": "user", "content": prompt}],
            )
            return response.choices[0].message.content

        raise ValueError(f"ä¸æ”¯æŒçš„provider: {self.provider}")

    def _parse_generated_content(self, content: str, paper_title: str) -> GeneratedArticle:
        """è§£æLLMç”Ÿæˆçš„å†…å®¹"""
        import re

        # æå–æ ‡é¢˜ï¼ˆç¬¬ä¸€ä¸ª#å¼€å¤´çš„è¡Œï¼‰
        title_match = re.search(r"^#\s+(.+)$", content, re.MULTILINE)
        title = title_match.group(1) if title_match else paper_title

        # æå–é…å›¾å ä½ç¬¦
        image_placeholders = []
        placeholder_pattern = r"<!--\s*IMAGE:\s*(.+?)\s*-->"
        for match in re.finditer(placeholder_pattern, content):
            image_placeholders.append({
                "position": match.start(),
                "description": match.group(1),
                "placeholder": match.group(0),
            })

        # è®¡ç®—å­—æ•°ï¼ˆä¸­æ–‡+è‹±æ–‡å•è¯ï¼‰
        chinese_chars = len(re.findall(r"[\u4e00-\u9fff]", content))
        english_words = len(re.findall(r"[a-zA-Z]+", content))
        word_count = chinese_chars + english_words

        return GeneratedArticle(
            title=title,
            content=content,
            image_placeholders=image_placeholders,
            word_count=word_count,
            paper_title=paper_title,
        )


if __name__ == "__main__":
    # æµ‹è¯•
    from ..parser.pdf_parser import parse_paper

    paper = parse_paper("https://arxiv.org/abs/1706.03762")
    writer = ArticleWriter()
    article = writer.generate(paper, citations=100000)
    print(f"\n{'='*50}")
    print(article.content[:1000])
